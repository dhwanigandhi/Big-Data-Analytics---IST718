{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "checksum": "4e6cefb0049d48a2f4648d752841bb06",
     "grade": false,
     "grade_id": "cell-b038e38b5e3072a9",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "# IST 718: Big Data Analytics\n",
    "\n",
    "- Prepared by: Prof Daniel E Acuna <deacuna@syr.edu>\n",
    "- Modified by: Prof Humayun Khan <hhkhan@syr.edu>\n",
    "- Faculty Assistant: Eashani Deorukhkar <edeorukh@syr.edu>\n",
    "- Faculty Assistant: Yash Kapadia <ykapadia@syr.edu>\n",
    "\n",
    "## General instructions:\n",
    "\n",
    "- You are welcome to discuss the problems with your classmates but __you are not allowed to copy any part of your answers from your classmates.  Short code snippets are allowed from the internet.  Code from the class text books or class provided code can be copied in its entirety.__\n",
    "- __Do not change homework file names.__ The FAs and the professor use these names to grade your homework.  Changing file names may result in a point reduction penalty.\n",
    "- There could be tests in some cells (i.e., `assert` and `np.testing.` statements). These tests (if present) are used to grade your answers. **However, the professor and FAs could use __additional__ test for your answer. Think about cases where your code should run even if it passess all the tests you see.**\n",
    "- Before submitting your work, remember to check for run time errors with the following procedure:\n",
    "`Kernel`$\\rightarrow$`Restart and Run All`.\n",
    "- All plots shall include a title, and axis labels.\n",
    "- Grading feedback cells are there for graders to provide feedback to students.  Don't change or remove grading feedback cells.\n",
    "- Good Luck!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load these packages\n",
    "import findspark\n",
    "findspark.init()\n",
    "\n",
    "import pyspark\n",
    "from pyspark.ml import feature, classification\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.sql import functions as fn\n",
    "import numpy as np\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml import feature, regression, evaluation, Pipeline\n",
    "from pyspark.sql import functions as fn, Row\n",
    "import matplotlib.pyplot as plt\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "sc = spark.sparkContext\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1: Random Forest and gradient boosted trees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In these questions, we will examine the famous [Auto dataset](https://vincentarelbundock.github.io/Rdatasets/doc/ISLR/Auto.html). With this dataset, the goal is to predict the miles per gallon (`mpg`) performance based on characteristics of the car such as number of cylinders (`cylinders`), displacement between wheels (`displacement`), horsepower of the engine (`horsepower`), weight of the car (`weight`), top acceleration (`acceleration`), year of the model (`year`), and origin (`origin`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "nbgrader": {
     "checksum": "d835a01d8146fbfa5aed060dae16d9fb",
     "grade": false,
     "grade_id": "cell-219523fd6f45f014",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- mpg: double (nullable = true)\n",
      " |-- cylinders: integer (nullable = true)\n",
      " |-- displacement: double (nullable = true)\n",
      " |-- weight: integer (nullable = true)\n",
      " |-- acceleration: double (nullable = true)\n",
      " |-- year: integer (nullable = true)\n",
      " |-- origin: integer (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- horsepower: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# data\n",
    "mpg_df = spark.read.csv('Auto.csv', header=True, inferSchema=True).\\\n",
    "    drop('_c0').\\\n",
    "    withColumn('horsepower2', fn.col('horsepower').cast('int')).\\\n",
    "    drop('horsepower').\\\n",
    "    withColumnRenamed('horsepower2', 'horsepower').\\\n",
    "    dropna()\n",
    "training_df, validation_df, testing_df = mpg_df.randomSplit([0.6, 0.3, 0.1], seed=0)\n",
    "mpg_df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 1: (20 pts)\n",
    "\n",
    "Create three pipelines that contain three different random forests that take in all features from `mpg_df` (`cylinders`, `displacement`, `horsepower`, `weight`, `acceleration`, `year`, and `origin`) to predict (`mpg`). **Set the `seed` parameter of the random forest to 0.** Fit these pipelines to the training data (`training_df`):\n",
    "\n",
    "- `pipe_rf1`: Random forest with `maxDepth=1` and `numTrees=60`\n",
    "- `pipe_rf2`: Random forest with `maxDepth=3` and `numTrees=40`\n",
    "- `pipe_rf3`: Random forest with `maxDepth=6`, `numTrees=20`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "nbgrader": {
     "checksum": "2912f0aa0562283b8c2b9b8d330a9e8c",
     "grade": false,
     "grade_id": "cell-5d34f31b40350198",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# create the fitted pipelines `pipe_rf1`, `pipe_rf2`, and `pipe_rf3` here\n",
    "from pyspark.ml.regression import RandomForestRegressor\n",
    "\n",
    "pipe_rf1=Pipeline(stages=[feature.VectorAssembler(inputCols=['cylinders', 'displacement', 'horsepower', 'weight', 'acceleration', 'year', 'origin'],outputCol='features'),RandomForestRegressor(featuresCol='features',labelCol='mpg',maxDepth=1,numTrees=60,seed=0)]).fit(training_df)\n",
    "pipe_rf2=Pipeline(stages=[feature.VectorAssembler(inputCols=['cylinders', 'displacement', 'horsepower', 'weight', 'acceleration', 'year', 'origin'],outputCol='features'),RandomForestRegressor(featuresCol='features',labelCol='mpg',maxDepth=3,numTrees=40,seed=0)]).fit(training_df)\n",
    "pipe_rf3=Pipeline(stages=[feature.VectorAssembler(inputCols=['cylinders', 'displacement', 'horsepower', 'weight', 'acceleration', 'year', 'origin'],outputCol='features'),RandomForestRegressor(featuresCol='features',labelCol='mpg',maxDepth=6,numTrees=20,seed=0)]).fit(training_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "nbgrader": {
     "checksum": "ab0fe44d4fffc964b8d76f2d7cc0bc52",
     "grade": true,
     "grade_id": "cell-896bdef9bf893231",
     "locked": true,
     "points": 10,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# tests\n",
    "np.testing.assert_equal(type(pipe_rf1.stages[0]), feature.VectorAssembler)\n",
    "np.testing.assert_equal(type(pipe_rf2.stages[0]), feature.VectorAssembler)\n",
    "np.testing.assert_equal(type(pipe_rf3.stages[0]), feature.VectorAssembler)\n",
    "np.testing.assert_equal(type(pipe_rf1.stages[1]), regression.RandomForestRegressionModel)\n",
    "np.testing.assert_equal(type(pipe_rf2.stages[1]), regression.RandomForestRegressionModel)\n",
    "np.testing.assert_equal(type(pipe_rf3.stages[1]), regression.RandomForestRegressionModel)\n",
    "np.testing.assert_equal(type(pipe_rf1.transform(training_df)), pyspark.sql.dataframe.DataFrame)\n",
    "np.testing.assert_equal(type(pipe_rf2.transform(training_df)), pyspark.sql.dataframe.DataFrame)\n",
    "np.testing.assert_equal(type(pipe_rf3.transform(training_df)), pyspark.sql.dataframe.DataFrame)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 2 (20 pts)\n",
    "\n",
    "Use the following evaluator to compute the $R^2$ of the models on validation data. Assign the $R^2$ of the three models to `R2_1`, `R2_2`, and `R2_3`, respectively, and the performance. Assign the best pipeline based on validation performance to a variable `best_model`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator = evaluation.RegressionEvaluator(labelCol='mpg', metricName='r2')\n",
    "# use it as follows:\n",
    "#   evaluator.evaluate(fitted_pipeline.transform(df)) -> R2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "nbgrader": {
     "checksum": "05aa55bb93c8241e41bb5608503701cc",
     "grade": false,
     "grade_id": "cell-91cd57be67b86f2a",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6356640531609501\n",
      "0.8222168008753123\n",
      "0.8833324964226545\n"
     ]
    }
   ],
   "source": [
    "# YOUR CODE HERE\n",
    "R2_1=evaluator.evaluate(pipe_rf1.transform(validation_df))\n",
    "R2_2=evaluator.evaluate(pipe_rf2.transform(validation_df))\n",
    "R2_3=evaluator.evaluate(pipe_rf3.transform(validation_df))\n",
    "print(R2_1)\n",
    "print(R2_2)\n",
    "print(R2_3)\n",
    "best_model=pipe_rf3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "nbgrader": {
     "checksum": "f54b5ffaa1b173049912fcc6e5153295",
     "grade": true,
     "grade_id": "cell-5399ae6afb414351",
     "locked": true,
     "points": 10,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# tests\n",
    "np.testing.assert_equal(type(best_model.stages[0]), feature.VectorAssembler)\n",
    "np.testing.assert_equal(type(best_model.stages[1]), regression.RandomForestRegressionModel)\n",
    "np.testing.assert_equal(type(best_model.transform(validation_df)), pyspark.sql.dataframe.DataFrame)\n",
    "np.testing.assert_array_less(R2_1, 1.)\n",
    "np.testing.assert_array_less(0.5, R2_1)\n",
    "np.testing.assert_array_less(R2_2, 1.)\n",
    "np.testing.assert_array_less(0.5, R2_2)\n",
    "np.testing.assert_array_less(R2_3, 1.)\n",
    "np.testing.assert_array_less(0.5, R2_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 3: 10 pts\n",
    "\n",
    "Compute the $R^2$ of the model on testing data, print it, and assign it to variable `R2_best`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "nbgrader": {
     "checksum": "d024cc767cf9091d250f11c6c26fc729",
     "grade": false,
     "grade_id": "cell-86f5f0eaa917209f",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8116746291631238\n"
     ]
    }
   ],
   "source": [
    "# create AUC_best below\n",
    "# YOUR CODE HERE\n",
    "R2_best=evaluator.evaluate(pipe_rf3.transform(testing_df))\n",
    "print(R2_best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "nbgrader": {
     "checksum": "be06b9c3fd35043998cada2e4c82af63",
     "grade": true,
     "grade_id": "cell-bd2f7d28b44ac691",
     "locked": true,
     "points": 5,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# tests\n",
    "np.testing.assert_array_less(R2_best, 1.)\n",
    "np.testing.assert_array_less(0.5, R2_best)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 4: 10 pts\n",
    "\n",
    "Using the parameters of the best model, create a new pipeline called `final_model` and fit it to the entire data (`mpg_df`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "nbgrader": {
     "checksum": "f1e9753be63f387d37db812d4102e26c",
     "grade": false,
     "grade_id": "cell-2574a5ca8f12ce94",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# create the fitted pipeline `final_model` here\n",
    "# YOUR CODE HERE\n",
    "final_model=Pipeline(stages=[feature.VectorAssembler(inputCols=['cylinders', 'displacement', 'horsepower', 'weight', 'acceleration', 'year', 'origin'],outputCol='features'),RandomForestRegressor(featuresCol='features',labelCol='mpg',maxDepth=6,numTrees=20,seed=0)]).fit(mpg_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "nbgrader": {
     "checksum": "10209c86da7aca0f6d99708efb051f44",
     "grade": true,
     "grade_id": "cell-bcce92747a0d2ba5",
     "locked": true,
     "points": 5,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# tests\n",
    "np.testing.assert_equal(type(final_model.stages[0]), feature.VectorAssembler)\n",
    "np.testing.assert_equal(type(final_model.stages[1]), regression.RandomForestRegressionModel)\n",
    "np.testing.assert_equal(type(final_model.transform(mpg_df)), pyspark.sql.dataframe.DataFrame)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 5: 10 pts\n",
    "\n",
    "Create a pandas dataframe `feature_importance` with the columns `feature` and `importance` which contains the names of the features (`cylinder`, `displacement`, etc.) and their feature importances as determined by the random forest of the final model. Sort the dataframe by `importance` in descending order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "nbgrader": {
     "checksum": "89dc0c52dff983147af006f48049dd3e",
     "grade": false,
     "grade_id": "cell-5b666b921af5a375",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# create feature_importance below\n",
    "# YOUR CODE HERE\n",
    "feature_importance=pd.DataFrame(list(zip(final_model.stages[0].getInputCols(),final_model.stages[1].featureImportances)),columns=['feature','importance']).sort_values('importance',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>displacement</td>\n",
       "      <td>0.379758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>horsepower</td>\n",
       "      <td>0.172883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>weight</td>\n",
       "      <td>0.143796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cylinders</td>\n",
       "      <td>0.134298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>year</td>\n",
       "      <td>0.133876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>acceleration</td>\n",
       "      <td>0.024922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>origin</td>\n",
       "      <td>0.010467</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        feature  importance\n",
       "1  displacement    0.379758\n",
       "2    horsepower    0.172883\n",
       "3        weight    0.143796\n",
       "0     cylinders    0.134298\n",
       "5          year    0.133876\n",
       "4  acceleration    0.024922\n",
       "6        origin    0.010467"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# display it here\n",
    "feature_importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "nbgrader": {
     "checksum": "a174ad97cc20a8fe9385ded1a56597f7",
     "grade": true,
     "grade_id": "cell-de7873ad0b54f277",
     "locked": true,
     "points": 10,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# tests\n",
    "assert type(feature_importance) == pd.core.frame.DataFrame\n",
    "np.testing.assert_array_equal(list(feature_importance.columns), ['feature', 'importance'])\n",
    "np.testing.assert_array_equal(list(feature_importance.columns), ['feature', 'importance'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comment below on the importance that random forest has given to each feature. Are they reasonable? Do they tell you anything valuable about the mpg dataset? Answer in the cell below"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "checksum": "b2c41f651112504fa5bc52db64459564",
     "grade": true,
     "grade_id": "cell-cd1eb09a9ba5aaa9",
     "locked": false,
     "points": 5,
     "schema_version": 1,
     "solution": true
    }
   },
   "source": [
    "***The random forest has given the highest importance to displacement followed by horsepower. The least importance is given to acceleration and origin. The features with more importance help in determining the mpg.***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 6:  10 pts.\n",
    "\n",
    "Pick any of the trees from the final model and assign its `toDebugString` property to a variable `example_tree`. Print this variable and add comments to the cell describing how you think this particular tree is fitting the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "nbgrader": {
     "checksum": "b212587e3d2f28ad35f04e2a6149e762",
     "grade": false,
     "grade_id": "cell-7476baa7ceb72c05",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeRegressionModel: uid=dtr_80ab275624c1, depth=6, numNodes=87, numFeatures=7\n",
      "  If (feature 1 <= 182.0)\n",
      "   If (feature 3 <= 2224.5)\n",
      "    If (feature 4 <= 21.25)\n",
      "     If (feature 2 <= 74.5)\n",
      "      If (feature 6 <= 2.5)\n",
      "       If (feature 5 <= 77.5)\n",
      "        Predict: 28.416666666666668\n",
      "       Else (feature 5 > 77.5)\n",
      "        Predict: 34.67727272727273\n",
      "      Else (feature 6 > 2.5)\n",
      "       If (feature 1 <= 93.5)\n",
      "        Predict: 36.08461538461539\n",
      "       Else (feature 1 > 93.5)\n",
      "        Predict: 31.316666666666645\n",
      "     Else (feature 2 > 74.5)\n",
      "      If (feature 4 <= 13.75)\n",
      "       Predict: 18.0\n",
      "      Else (feature 4 > 13.75)\n",
      "       If (feature 1 <= 113.5)\n",
      "        Predict: 29.6875\n",
      "       Else (feature 1 > 113.5)\n",
      "        Predict: 25.5\n",
      "    Else (feature 4 > 21.25)\n",
      "     If (feature 3 <= 2139.5)\n",
      "      Predict: 44.224999999999994\n",
      "     Else (feature 3 > 2139.5)\n",
      "      Predict: 24.5\n",
      "   Else (feature 3 > 2224.5)\n",
      "    If (feature 2 <= 84.5)\n",
      "     If (feature 2 <= 63.5)\n",
      "      Predict: 23.0\n",
      "     Else (feature 2 > 63.5)\n",
      "      If (feature 1 <= 120.5)\n",
      "       If (feature 6 <= 1.5)\n",
      "        Predict: 30.72\n",
      "       Else (feature 6 > 1.5)\n",
      "        Predict: 32.4\n",
      "      Else (feature 1 > 120.5)\n",
      "       If (feature 5 <= 76.5)\n",
      "        Predict: 24.555555555555557\n",
      "       Else (feature 5 > 76.5)\n",
      "        Predict: 30.482352941176465\n",
      "    Else (feature 2 > 84.5)\n",
      "     If (feature 5 <= 78.5)\n",
      "      If (feature 0 <= 4.5)\n",
      "       If (feature 3 <= 2902.5)\n",
      "        Predict: 23.93888888888889\n",
      "       Else (feature 3 > 2902.5)\n",
      "        Predict: 20.0\n",
      "      Else (feature 0 > 4.5)\n",
      "       If (feature 1 <= 159.5)\n",
      "        Predict: 20.05\n",
      "       Else (feature 1 > 159.5)\n",
      "        Predict: 17.66666666666667\n",
      "     Else (feature 5 > 78.5)\n",
      "      If (feature 1 <= 126.0)\n",
      "       If (feature 1 <= 113.5)\n",
      "        Predict: 28.339999999999996\n",
      "       Else (feature 1 > 113.5)\n",
      "        Predict: 34.96666666666667\n",
      "      Else (feature 1 > 126.0)\n",
      "       If (feature 2 <= 127.0)\n",
      "        Predict: 26.334615384615386\n",
      "       Else (feature 2 > 127.0)\n",
      "        Predict: 32.700000000000045\n",
      "  Else (feature 1 > 182.0)\n",
      "   If (feature 2 <= 127.0)\n",
      "    If (feature 4 <= 16.55)\n",
      "     If (feature 3 <= 3732.5)\n",
      "      If (feature 1 <= 212.5)\n",
      "       If (feature 5 <= 70.5)\n",
      "        Predict: 20.333333333333332\n",
      "       Else (feature 5 > 70.5)\n",
      "        Predict: 20.0\n",
      "      Else (feature 1 > 212.5)\n",
      "       If (feature 2 <= 107.5)\n",
      "        Predict: 18.488888888888887\n",
      "       Else (feature 2 > 107.5)\n",
      "        Predict: 19.611111111111118\n",
      "     Else (feature 3 > 3732.5)\n",
      "      Predict: 15.5\n",
      "    Else (feature 4 > 16.55)\n",
      "     If (feature 5 <= 81.5)\n",
      "      If (feature 5 <= 75.5)\n",
      "       If (feature 1 <= 241.0)\n",
      "        Predict: 18.666666666666668\n",
      "       Else (feature 1 > 241.0)\n",
      "        Predict: 15.666666666666666\n",
      "      Else (feature 5 > 75.5)\n",
      "       If (feature 2 <= 90.5)\n",
      "        Predict: 22.014285714285716\n",
      "       Else (feature 2 > 90.5)\n",
      "        Predict: 20.213333333333335\n",
      "     Else (feature 5 > 81.5)\n",
      "      Predict: 38.0\n",
      "   Else (feature 2 > 127.0)\n",
      "    If (feature 5 <= 76.5)\n",
      "     If (feature 4 <= 16.299999999999997)\n",
      "      If (feature 3 <= 3616.5)\n",
      "       If (feature 5 <= 73.5)\n",
      "        Predict: 15.875\n",
      "       Else (feature 5 > 73.5)\n",
      "        Predict: 13.0\n",
      "      Else (feature 3 > 3616.5)\n",
      "       If (feature 3 <= 4655.5)\n",
      "        Predict: 13.9453125\n",
      "       Else (feature 3 > 4655.5)\n",
      "        Predict: 12.833333333333334\n",
      "     Else (feature 4 > 16.299999999999997)\n",
      "      Predict: 9.0\n",
      "    Else (feature 5 > 76.5)\n",
      "     If (feature 4 <= 13.75)\n",
      "      If (feature 1 <= 329.0)\n",
      "       If (feature 3 <= 3616.5)\n",
      "        Predict: 19.166666666666668\n",
      "       Else (feature 3 > 3616.5)\n",
      "        Predict: 17.814285714285717\n",
      "      Else (feature 1 > 329.0)\n",
      "       If (feature 4 <= 13.1)\n",
      "        Predict: 18.5\n",
      "       Else (feature 4 > 13.1)\n",
      "        Predict: 16.5\n",
      "     Else (feature 4 > 13.75)\n",
      "      If (feature 3 <= 3886.0)\n",
      "       Predict: 17.0\n",
      "      Else (feature 3 > 3886.0)\n",
      "       If (feature 2 <= 143.5)\n",
      "        Predict: 15.166666666666666\n",
      "       Else (feature 2 > 143.5)\n",
      "        Predict: 16.9\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# create a variable example_tree with the toDebugString property of a tree from final_model.\n",
    "# print this string and comment in this same cell about the branches that this tree fit\n",
    "# YOUR CODE HERE\n",
    "\n",
    "example_tree = final_model.stages[1].trees[14].toDebugString\n",
    "print(example_tree)\n",
    "\n",
    "#The feature at the top of the tree checks if feature 1 i.e. displacement is less than or equal to 182.0, if yes it checks if feature 3 i.e. weight is less than or equal to 2224.5. \n",
    "#This continues further till the if condition is false. It then goes into the else loop and checks the condition. Each time it predicts a value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "nbgrader": {
     "checksum": "9f35c194d03338e1a9e24d771fb28c2e",
     "grade": true,
     "grade_id": "cell-80c89e10a60f6ce2",
     "locked": true,
     "points": 5,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# tests\n",
    "assert type(example_tree) == str\n",
    "assert 'DecisionTreeRegressionModel' in example_tree\n",
    "assert 'feature 0' in example_tree\n",
    "assert 'If' in example_tree\n",
    "assert 'Else' in example_tree\n",
    "assert 'Predict' in example_tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Question 7 (20 pts)**\n",
    "\n",
    "Gradient boosted trees are becoming increasingly popular for competitions. There is a high-performance implementation, [xgboost](https://en.wikipedia.org/wiki/XGBoost), that is particularly popular. Compare gradient boosted regression to the best model found with random forest in Question 3. Use the validation set. For GBR, use all the default parameters except make `seed=0`. Assign the pipeline and the $R^2$ of the model to `gbr_pipe` and `R2_gbr`, respectively. Does it have an amazing or dissapointing $R^2$? Comment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "nbgrader": {
     "checksum": "d399ce658c943b8f572a428367c1725e",
     "grade": false,
     "grade_id": "cell-edab7ea019e8b267",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "from pyspark.ml.regression import GBTRegressor\n",
    "\n",
    "gbr_pipe=Pipeline(stages=[feature.VectorAssembler(inputCols=['cylinders', 'displacement', 'horsepower', 'weight', 'acceleration', 'year', 'origin'],outputCol='features'),GBTRegressor(featuresCol='features',labelCol='mpg',seed=0)]).fit(training_df)\n",
    "R2_gbr=evaluator.evaluate(gbr_pipe.transform(validation_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance of best RF:  0.8833324964226545\n",
      "Performance of GBR:  0.8404903251080562\n"
     ]
    }
   ],
   "source": [
    "# test your models here\n",
    "print(\"Performance of best RF: \", evaluator.evaluate(best_model.transform(validation_df)))\n",
    "print(\"Performance of GBR: \", R2_gbr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "nbgrader": {
     "checksum": "7636ddf552f508aaa5952350f9b0a210",
     "grade": true,
     "grade_id": "cell-f7b1ed961851c406",
     "locked": true,
     "points": 5,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# tests\n",
    "np.testing.assert_equal(type(gbr_pipe.stages[0]), feature.VectorAssembler)\n",
    "np.testing.assert_equal(type(gbr_pipe.stages[1]), regression.GBTRegressionModel)\n",
    "np.testing.assert_equal(type(gbr_pipe.transform(validation_df)), pyspark.sql.dataframe.DataFrame)\n",
    "np.testing.assert_array_less(R2_gbr, 1.)\n",
    "np.testing.assert_array_less(0.5, R2_gbr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***The R^2 value of the best model found with random forest is better than the R^2 value of the Gradient Boosted Tree model, but the R^2 value of the GBT model is not dissapointing either.***"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Edit Metadata",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
